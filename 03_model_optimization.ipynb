{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T12:48:00.481798Z",
     "start_time": "2025-12-05T12:48:00.477405Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:48:01.364787Z",
     "start_time": "2025-12-05T12:48:00.502839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"hatalı.csv\")\n",
    "print(f\"data tüklendi {df.shape}\")\n",
    "print(f\"Fraud sayısı {df[\"Class\"].sum()}\")"
   ],
   "id": "d0910e00c041af8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data tüklendi (284807, 31)\n",
      "Fraud sayısı 492\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:48:01.463717Z",
     "start_time": "2025-12-05T12:48:01.427556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SCALING - Time ve Amount'u normalize et\n",
    "scaler_time = StandardScaler()\n",
    "scaler_amount = StandardScaler()\n",
    "df['Time_Scaled'] = scaler_time.fit_transform(df[['Time']])\n",
    "df['Amount_Scaled'] = scaler_amount.fit_transform(df[['Amount']])\n",
    "\n",
    "# AMOUNT FEATURES\n",
    "df['Amount_Log'] = np.log1p(df['Amount'])  # log transformation\n",
    "df['Is_Small_Amount'] = (df['Amount'] < 10).astype(int)  # 10$'dan kucuk mu?\n",
    "df['Is_Large_Amount'] = (df['Amount'] > 200).astype(int)  # 200$'dan buyuk mu?\n",
    "\n",
    "# TIME FEATURES\n",
    "df['Time_Hours'] = df['Time'] / 3600  # saniye -> saat\n",
    "df['Hour'] = (df['Time_Hours'] % 24).astype(int)  # 0-23 arasi saat\n",
    "df['Is_Night'] = ((df['Hour'] >= 22) | (df['Hour'] <= 6)).astype(int)  # gece mi?\n",
    "\n",
    "# V INTERACTIONS\n",
    "df['V17_V14'] = df['V17'] * df['V14']  # en guclu 2 feature'i carp\n",
    "df['Top5_sum'] = df['V17'] + df['V14'] + df['V12'] + df['V10'] + df['V16']  # top 5 topla\n",
    "\n",
    "print(\"Tum feature'lar olusturuldu!\")"
   ],
   "id": "550f48225372957a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tum feature'lar olusturuldu!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:48:01.655305Z",
     "start_time": "2025-12-05T12:48:01.499802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FEATURE LİSTESİ - 37 feature\n",
    "features = [\n",
    "    'Time_Scaled', 'Amount_Scaled',\n",
    "    'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "    'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "    'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
    "    'Amount_Log', 'Is_Small_Amount', 'Is_Large_Amount',\n",
    "    'Hour', 'Is_Night',\n",
    "    'V17_V14', 'Top5_sum'\n",
    "]\n",
    "\n",
    "# X ve y hazirla\n",
    "X = df[features]\n",
    "y = df['Class']\n",
    "\n",
    "# TRAIN/TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,  # %20 test\n",
    "    random_state=42,  # tekrar edilebilir\n",
    "    stratify=y  # fraud oranini koru\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "print(f\"Feature sayisi: {len(features)}\")"
   ],
   "id": "700221241b680e32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (227845, 37)\n",
      "Test: (56962, 37)\n",
      "Feature sayisi: 37\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:48:05.323873Z",
     "start_time": "2025-12-05T12:48:01.666155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LIGHTGBM MODEL - IYILESTIRILMIS\n",
    "print(\"LightGBM egitiliyor...\")\n",
    "\n",
    "# Imbalance ratio\n",
    "imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "# Model olustur - DAHA IYI PARAMETRELER\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,              #\n",
    "    learning_rate=0.05,            #\n",
    "    max_depth=7,                   #\n",
    "    num_leaves=31,                 #\n",
    "    min_child_samples=20,          #\n",
    "    scale_pos_weight=imbalance_ratio,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Egit\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin\n",
    "y_train_pred_lgb = lgb_model.predict_proba(X_train)[:, 1]\n",
    "y_test_pred_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Skorlar\n",
    "train_auc_lgb = roc_auc_score(y_train, y_train_pred_lgb)\n",
    "test_auc_lgb = roc_auc_score(y_test, y_test_pred_lgb)\n",
    "\n",
    "print(\"\\nSONUCLAR:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Logistic Regression Test AUC: 0.9750\")\n",
    "print(f\"LightGBM Train AUC: {train_auc_lgb:.4f}\")\n",
    "print(f\"LightGBM Test AUC:  {test_auc_lgb:.4f}\")\n",
    "print(f\"Improvement: {test_auc_lgb - 0.9750:.4f}\")\n",
    "print(\"=\"*50)"
   ],
   "id": "862726c6abf8ed56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM egitiliyor...\n",
      "Imbalance ratio: 577.3:1\n",
      "\n",
      "SONUCLAR:\n",
      "==================================================\n",
      "Logistic Regression Test AUC: 0.9750\n",
      "LightGBM Train AUC: 0.9349\n",
      "LightGBM Test AUC:  0.9137\n",
      "Improvement: -0.0613\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:51:20.098347Z",
     "start_time": "2025-12-05T12:51:20.090576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def test_lgb_params(n_estimators, learning_rate, max_depth, num_leaves):\n",
    "    \"\"\"\n",
    "    Verilen parametrelerle LightGBM'i CV ile test et\n",
    "    \"\"\"\n",
    "    # Imbalance ratio\n",
    "    imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "    # Model olustur\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=20,\n",
    "        scale_pos_weight=imbalance_ratio,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    # 5-Fold CV\n",
    "    cv_scores = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,              # 5 fold\n",
    "        scoring='roc_auc', # AUC metrik\n",
    "        n_jobs=-1          # tum cekirdekler\n",
    "    )\n",
    "\n",
    "    mean_score = cv_scores.mean()\n",
    "    std_score = cv_scores.std()\n",
    "\n",
    "    return mean_score, std_score\n",
    "\n",
    "print(\"CV fonksiyonu hazir\")"
   ],
   "id": "22a42df3a7f2af2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fonksiyonu hazir!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:52:46.777506Z",
     "start_time": "2025-12-05T12:51:39.183442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Test edilecek parametreler\n",
    "param_grid = [\n",
    "    # (n_estimators, learning_rate, max_depth, num_leaves)\n",
    "    (300, 0.05, 6, 31),\n",
    "    (500, 0.05, 6, 31),\n",
    "    (300, 0.03, 7, 31),\n",
    "    (500, 0.03, 7, 31),\n",
    "    (500, 0.05, 7, 63),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (n_est, lr, depth, leaves) in enumerate(param_grid, 1):\n",
    "    print(f\"Test {i}/{len(param_grid)}: n_est={n_est}, lr={lr}, depth={depth}, leaves={leaves}\")\n",
    "\n",
    "    mean_score, std_score = test_lgb_params(n_est, lr, depth, leaves)\n",
    "\n",
    "    results.append({\n",
    "        'n_estimators': n_est,\n",
    "        'learning_rate': lr,\n",
    "        'max_depth': depth,\n",
    "        'num_leaves': leaves,\n",
    "        'mean_auc': mean_score,\n",
    "        'std_auc': std_score\n",
    "    })\n",
    "\n",
    "    print(f\"  -> CV AUC: {mean_score:.4f} (+/- {std_score:.4f})\\n\")\n",
    "\n",
    "# Sonuclari dataframe'e cevir\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('mean_auc', ascending=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EN IYI 5 SONUC:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))"
   ],
   "id": "d105ee7148233074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETER TUNING BASLIYOR...\n",
      "Bu ~20-30 dakika surecek, lutfen bekleyin!\n",
      "\n",
      "Test 1/5: n_est=300, lr=0.05, depth=6, leaves=31\n",
      "  -> CV AUC: 0.8758 (+/- 0.0604)\n",
      "\n",
      "Test 2/5: n_est=500, lr=0.05, depth=6, leaves=31\n",
      "  -> CV AUC: 0.8590 (+/- 0.0485)\n",
      "\n",
      "Test 3/5: n_est=300, lr=0.03, depth=7, leaves=31\n",
      "  -> CV AUC: 0.8682 (+/- 0.0298)\n",
      "\n",
      "Test 4/5: n_est=500, lr=0.03, depth=7, leaves=31\n",
      "  -> CV AUC: 0.8914 (+/- 0.0066)\n",
      "\n",
      "Test 5/5: n_est=500, lr=0.05, depth=7, leaves=63\n",
      "  -> CV AUC: 0.8391 (+/- 0.1042)\n",
      "\n",
      "======================================================================\n",
      "EN IYI 5 SONUC:\n",
      "======================================================================\n",
      " n_estimators  learning_rate  max_depth  num_leaves  mean_auc  std_auc\n",
      "          500           0.03          7          31  0.891431 0.006577\n",
      "          300           0.05          6          31  0.875803 0.060415\n",
      "          300           0.03          7          31  0.868159 0.029784\n",
      "          500           0.05          6          31  0.859004 0.048507\n",
      "          500           0.05          7          63  0.839119 0.104179\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LightGBM denedim, CV ile hyperparameter tuning yaptım, ama Logistic Regression daha iyi oldu. Çünkü dataset PCA'lanmış ve linear separable. Karmaşık model her zaman iyi olmuyor!",
   "id": "495975bfe83d32c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25df18b2747508ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
